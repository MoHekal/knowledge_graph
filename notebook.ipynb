{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Powered Consultancy Graph Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "1. Configuration\n",
    "2. Helper Functions\n",
    "3. Prompts\n",
    "4. Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai) (2024.7.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (1.9.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\aa10098\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\aa10098\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (5.24.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\aa10098\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from neo4j) (2024.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\aa10098\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install python-dotenv\n",
    "!pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from string import Template\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "import glob\n",
    "from timeit import default_timer as timer\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j configuration & constraints\n",
    "neo4j_url = os.getenv(\"NEO4J_CONNECTION_URL\")\n",
    "neo4j_user = os.getenv(\"NEO4J_USER\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "gds = GraphDatabase.driver(neo4j_url, auth=(neo4j_user, neo4j_password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call the OpenAI API\n",
    "def process_gpt(file_prompt, system_msg):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\", \n",
    "        max_tokens=7000,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": file_prompt},\n",
    "        ],\n",
    "    )\n",
    "    nlp_results = completion.choices[0].message['content']\n",
    "    sleep(8)\n",
    "    return nlp_results\n",
    "\n",
    "# Example usage\n",
    "# result = process_gpt(\"What is the weather like today?\", \"Please provide a weather update.\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to take folder of files and a prompt template, and return a json-object of all the entities and relationships\n",
    "def extract_entities_relationships(folder, prompt_template):\n",
    "    start = timer()\n",
    "    files = glob.glob(f\"./data/{folder}/*\")\n",
    "    system_msg = \"You are a helpful IT-project and account management expert who extracts information from documents.\"\n",
    "    print(f\"Running pipeline for {len(files)} files in {folder} folder\")\n",
    "    results = []\n",
    "    for i, file in enumerate(files):\n",
    "        print(f\"Extracting entities and relationships for {file}\")\n",
    "        try:\n",
    "            with open(file, \"r\") as f:\n",
    "                text = f.read().rstrip()\n",
    "                prompt = Template(prompt_template).substitute(ctext=text)\n",
    "                result = process_gpt(prompt, system_msg=system_msg)\n",
    "                results.append(json.loads(result))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "    end = timer()\n",
    "    print(f\"Pipeline completed in {end-start} seconds\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# Function to take a json-object of entitites and relationships and generate cypher query for creating those entities\n",
    "def generate_cypher(json_obj):\n",
    "    e_statements = []\n",
    "    r_statements = []\n",
    "\n",
    "    e_label_map = {}\n",
    "\n",
    "    # loop through our json object\n",
    "    for i, obj in enumerate(json_obj):\n",
    "        print(f\"Generating cypher for file {i+1} of {len(json_obj)}\")\n",
    "        for entity in obj[\"entities\"]:\n",
    "            label = entity[\"label\"]\n",
    "            id = entity[\"id\"]\n",
    "            id = id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "            properties = {k: v for k, v in entity.items() if k not in [\"label\", \"id\"]}\n",
    "\n",
    "            cypher = f'MERGE (n:{label} {{id: \"{id}\"}})'\n",
    "            if properties:\n",
    "                props_str = \", \".join(\n",
    "                    [f'n.{key} = \"{val}\"' for key, val in properties.items()]\n",
    "                )\n",
    "                cypher += f\" ON CREATE SET {props_str}\"\n",
    "            e_statements.append(cypher)\n",
    "            e_label_map[id] = label\n",
    "\n",
    "        for rs in obj[\"relationships\"]:\n",
    "            src_id, rs_type, tgt_id = rs.split(\"|\")\n",
    "            src_id = src_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "            tgt_id = tgt_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "\n",
    "            src_label = e_label_map[src_id]\n",
    "            tgt_label = e_label_map[tgt_id]\n",
    "\n",
    "            cypher = f'MERGE (a:{src_label} {{id: \"{src_id}\"}}) MERGE (b:{tgt_label} {{id: \"{tgt_id}\"}}) MERGE (a)-[:{rs_type}]->(b)'\n",
    "            r_statements.append(cypher)\n",
    "\n",
    "    with open(\"cyphers.txt\", \"w\") as outfile:\n",
    "        outfile.write(\"\\n\".join(e_statements + r_statements))\n",
    "\n",
    "    return e_statements + r_statements\n",
    "\n",
    "\n",
    "# Final function to bring all the steps together\n",
    "def ingestion_pipeline(folders):\n",
    "    # Extrating the entites and relationships from each folder, append into one json_object\n",
    "    entities_relationships = []\n",
    "    for key, value in folders.items():\n",
    "        entities_relationships.extend(extract_entities_relationships(key, value))\n",
    "\n",
    "    # Generate and execute cypher statements\n",
    "    cypher_statements = generate_cypher(entities_relationships)\n",
    "    for i, stmt in enumerate(cypher_statements):\n",
    "        print(f\"Executing cypher statement {i+1} of {len(cypher_statements)}\")\n",
    "        try:\n",
    "            gds.execute_query(stmt)\n",
    "        except Exception as e:\n",
    "            with open(\"failed_statements.txt\", \"w\") as f:\n",
    "                f.write(f\"{stmt} - Exception: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for processing project briefs\n",
    "project_prompt_template = \"\"\"\n",
    "0. Answer in less than 6000 tokens.\n",
    "From the Project Brief below, extract the following Entities & relationships described below \n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. Document must be summarized and stored inside Project entity under `summary` property. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Project',id:string,name:string;summary:string //Project mentioned in the brief; `id` property is the full name of the project, in lowercase, with no capital letters, special characters, spaces or hyphens; Contents of original document must be summarized inside 'summary' property\n",
    "    label:'Technology',id:string,name:string //Technology Entity; `id` property is the name of the technology, in camel-case. Identify as many of the technologies used as possible\n",
    "    label:'Client',id:string,name:string;industry:string //Client that the project was done for; `id` property is the name of the Client, in camel-case; 'industry' is the industry that the client operates in, as mentioned in the project brief.\n",
    "    \n",
    "2. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    project|USES_TECH|technology \n",
    "    project|HAS_CLIENT|client\n",
    "\n",
    "\n",
    "3. The output should look like :\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Project\",\"id\":string,\"name\":string,\"summary\":string}],\n",
    "    \"relationships\": [\"projectid|USES_TECH|technologyid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Prompt for processing peoples' profiles\n",
    "people_prompt_template = \"\"\"\n",
    "0. Answer in less than 6000 tokens.\n",
    "From the list of people below, extract the following Entities & relationships described below \n",
    "\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Person',id:string,name:string //Person that the data is about. `id` property is the name of the person, in camel-case. 'name' is the person's name, as spelled in the text.\n",
    "    label:'Project',id:string,name:string;summary:string //Project mentioned in the profile; `id` property is the full lowercase name of the project, with no capital letters, special characters, spaces or hyphens.\n",
    "    label:'Technology',id:string,name:string //Technology Entity, as listed in the \"skills\"-section of every person; `id` property is the name of the technology, in camel-case.\n",
    "    \n",
    "3. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    person|HAS_SKILLS|technology \n",
    "    project|HAS_PEOPLE|person\n",
    "\n",
    "\n",
    "The output should look like :\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Person\",\"id\":string,\"name\":string}],\n",
    "    \"relationships\": [\"projectid|HAS_PEOPLE|personid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Prompt for processing slack messages\n",
    "\n",
    "slack_prompt_template = \"\"\"\n",
    "0. Answer in less than 6000 tokens.\n",
    "From the list of messages below, extract the following Entities & relationships described below \n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Person',id:string,name:string //Person that sent the message. `id` property is the name of the person, in camel-case; \n",
    "3. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    personid|SENT|slackmessageid\n",
    "\n",
    "The output should look like :\n",
    "{\n",
    "    \"entities\": [{\"label\":\"SlackMessage\",\"id\":string,\"text\":string}],\n",
    "    \"relationships\": [\"personid|SENT|messageid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Running the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline for 3 files in people_profiles folder\n",
      "Extracting entities and relationships for ./data/people_profiles\\people-profiles1.md\n",
      "Extracting entities and relationships for ./data/people_profiles\\people-profiles2.md\n",
      "Extracting entities and relationships for ./data/people_profiles\\people-profiles3.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 1.1028601286646116s (Unable to retrieve routing information)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline completed in 103.61848510010168 seconds\n",
      "Generating cypher for file 1 of 3\n",
      "Generating cypher for file 2 of 3\n",
      "Generating cypher for file 3 of 3\n",
      "Executing cypher statement 1 of 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 2.018190762992659s (Unable to retrieve routing information)\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 4.774438637165846s (Unable to retrieve routing information)\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 9.289107219423041s (Unable to retrieve routing information)\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 18.555197885392808s (Unable to retrieve routing information)\n"
     ]
    }
   ],
   "source": [
    "folders = {\n",
    "    \"people_profiles\": people_prompt_template,\n",
    "    #\"project_briefs\": project_prompt_template,\n",
    "    #\"slack_messages\": slack_prompt_template,\n",
    "}\n",
    "\n",
    "ingestion_pipeline(folders)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
